{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ddf92acc-82a9-4b93-b077-9ba6ea0d94bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9668825d-28ca-4a8c-b7cb-69e9f4624e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from catboost import CatBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "83355175-f778-4bf3-bf76-5028584aeb17",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('./data/ready_train.csv')\n",
    "test = pd.read_csv('./data/ready_test.csv')\n",
    "data = pd.read_csv('./data/preprocessed_full.csv')\n",
    "\n",
    "train_80 = train.sample(frac = 0.8, random_state = 42)\n",
    " \n",
    "# Creating dataframe with \n",
    "# rest of the 80% values\n",
    "train_hold = train.drop(train_80.index)\n",
    "\n",
    "test_hold = test.drop(train_80.index)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5970d5f2-15c0-4fdb-935e-069c13eed0bd",
   "metadata": {},
   "source": [
    "# Straightforward solutions\n",
    "Let's assume, that the best method for each time series is the method with the highest number of best results.\n",
    "The accuarcy we get from choosing that method for every time series and the average RMSSE for specified model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c1ae7ae3-ef8d-4675-851d-9840f4047700",
   "metadata": {},
   "outputs": [],
   "source": [
    "def straightforward(raw_data, best_data, criteria, models):\n",
    "    baseline = pd.DataFrame(index=criteria,\n",
    "                            columns=['metric', 'model', 'accuracy', 'lost_rate', 'RMSSE'])\n",
    "    assert np.array(models).shape == np.array(criteria).shape\n",
    "    baseline['metric'] = criteria\n",
    "    baseline['model'] = models\n",
    "\n",
    "    total = len(best_data)\n",
    "    for criterion, model in zip(criteria, models):\n",
    "        # Calculate accuarcy\n",
    "        tp = best_data[best_data[criterion+'_model']==model].count().iloc[0]\n",
    "        \n",
    "        true_results = raw_data[raw_data['model_name']==model]\n",
    "        n = 0; mae = 0; lost = 0; rmsse = 0\n",
    "        # For each time series calculate discrepancy between best result and\n",
    "        # predicted method\n",
    "        for ts, result in zip(best_data['naming_orig'], best_data[criterion]):\n",
    "            batch = true_results[true_results['naming_orig']==ts]\n",
    "            try:\n",
    "                true_value = batch.iloc[batch[criterion].argmin()][criterion]\n",
    "                rmsse = rmsse + true_value\n",
    "                if true_value != result:\n",
    "                    n = n + 1\n",
    "                    mae = mae + np.abs(true_value - result)\n",
    "            except:\n",
    "                lost = lost + 1\n",
    "            \n",
    "        #baseline.loc[criterion, 'MAE'] = mae / n\n",
    "        baseline.loc[criterion, 'lost_rate'] = lost / total\n",
    "        baseline.loc[criterion, 'accuracy'] = tp / total\n",
    "        baseline.loc[criterion, 'RMSSE'] = rmsse / total\n",
    "        baseline.index = np.arange(len(criteria))\n",
    "            \n",
    "    return baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79e7037b-370b-4dde-9910-dd4bfeda6fd8",
   "metadata": {},
   "source": [
    "## Experiment I\n",
    "We take the most frequent model from the **train** set and apply it to the **train** holdout as a prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1f5b8077-f7de-4b80-82a8-646c588fb370",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>lost_rate</th>\n",
       "      <th>RMSSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RMSSE</td>\n",
       "      <td>TFTTuningObjective_gl</td>\n",
       "      <td>0.149425</td>\n",
       "      <td>0.109195</td>\n",
       "      <td>0.839198</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  metric                  model  accuracy lost_rate     RMSSE\n",
       "0  RMSSE  TFTTuningObjective_gl  0.149425  0.109195  0.839198"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_train_model = train_80['RMSSE_model'].mode().to_numpy()[0]\n",
    "train_baseline = straightforward(data[data['split']=='validation'],\n",
    "                                 train_hold, ['RMSSE'], [best_train_model])\n",
    "train_baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3526c468-6308-4720-bf33-a23475b3015d",
   "metadata": {},
   "source": [
    "## Experiment II\n",
    "We take the most frequent model from the **train** set and apply it to the **test** holdout as a prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7d0338d4-e399-4571-9e31-cdff76d98ffb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>lost_rate</th>\n",
       "      <th>RMSSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RMSSE</td>\n",
       "      <td>TFTTuningObjective_gl</td>\n",
       "      <td>0.132184</td>\n",
       "      <td>0.109195</td>\n",
       "      <td>0.965092</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  metric                  model  accuracy lost_rate     RMSSE\n",
       "0  RMSSE  TFTTuningObjective_gl  0.132184  0.109195  0.965092"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_baseline = straightforward(data[data['split']=='test'],\n",
    "                              test_hold, ['RMSSE'], [best_train_model])\n",
    "cv_baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e99d8eb5-5b1b-4f3f-8c46-72354a140ac3",
   "metadata": {},
   "source": [
    "## Experiment III\n",
    "We take models from the **train** holdout and apply them to the **test** holdout as a prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6a2038d1-bc38-4188-9579-6369cba4ebc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation2test(raw_data, val_data, test_data, criteria):\n",
    "    result = pd.DataFrame(index=criteria,\n",
    "                          columns=['metric', 'model', 'accuracy', 'lost_rate', 'RMSSE'])\n",
    "    assert np.array(val_data).shape == np.array(test_data).shape\n",
    "    result['metric'] = criteria\n",
    "    result['model'] = 'N/A'\n",
    "    \n",
    "    total = len(val_data)\n",
    "    for criterion in criteria:\n",
    "        # Calculate accuarcy\n",
    "        tp = val_data[val_data[criterion+'_model']==test_data[criterion+'_model']].count().iloc[0]\n",
    "        \n",
    "        n = 0; mae = 0; lost = 0; rmsse = 0\n",
    "        \n",
    "        for ts, metric in zip(test_data['naming_orig'], test_data[criterion]):\n",
    "            batch = raw_data[raw_data['naming_orig']==ts]\n",
    "            batch_val = val_data[val_data['naming_orig']==ts]\n",
    "            value = batch[batch['model_name']==batch_val[criterion+'_model'].values[0]]\n",
    "            try:\n",
    "                true_value = value.iloc[value[criterion].argmin()][criterion]\n",
    "                rmsse = rmsse + true_value\n",
    "                if true_value != metric:\n",
    "                    n = n + 1\n",
    "                    mae = mae + np.abs(true_value - metric)\n",
    "            except:\n",
    "                lost = lost + 1\n",
    "            \n",
    "        #result.loc[criterion, 'MAE'] = mae / n\n",
    "        result.loc[criterion, 'lost_rate'] = lost / total\n",
    "        result.loc[criterion, 'accuracy'] = tp / total\n",
    "        result.loc[criterion, 'RMSSE'] = rmsse / total\n",
    "        result.index = np.arange(len(criteria))\n",
    "            \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a7700ea7-fe62-4fd4-a0e2-c876efad404a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>lost_rate</th>\n",
       "      <th>RMSSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RMSSE</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0.155172</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.887912</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  metric model  accuracy lost_rate     RMSSE\n",
       "0  RMSSE   N/A  0.155172       0.0  0.887912"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val2test = validation2test(data[data['split']=='test'], \n",
    "                           train_hold, test_hold, ['RMSSE'])\n",
    "val2test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa3f3b70-92a6-4ee3-a790-a068f34b63f1",
   "metadata": {},
   "source": [
    "# Classifier solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4752cbde-2728-4973-9f8b-122edbfa4728",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 2.9688227\ttotal: 179ms\tremaining: 3.04s\n",
      "1:\tlearn: 2.8317443\ttotal: 228ms\tremaining: 1.82s\n",
      "2:\tlearn: 2.7079429\ttotal: 278ms\tremaining: 1.39s\n",
      "3:\tlearn: 2.6069589\ttotal: 329ms\tremaining: 1.15s\n",
      "4:\tlearn: 2.4909748\ttotal: 379ms\tremaining: 985ms\n",
      "5:\tlearn: 2.4043156\ttotal: 430ms\tremaining: 859ms\n",
      "6:\tlearn: 2.3370352\ttotal: 478ms\tremaining: 752ms\n",
      "7:\tlearn: 2.2743725\ttotal: 526ms\tremaining: 657ms\n",
      "8:\tlearn: 2.2175726\ttotal: 572ms\tremaining: 572ms\n",
      "9:\tlearn: 2.1703629\ttotal: 622ms\tremaining: 498ms\n",
      "10:\tlearn: 2.1244625\ttotal: 673ms\tremaining: 428ms\n",
      "11:\tlearn: 2.0676530\ttotal: 731ms\tremaining: 366ms\n",
      "12:\tlearn: 2.0272019\ttotal: 777ms\tremaining: 299ms\n",
      "13:\tlearn: 1.9866064\ttotal: 823ms\tremaining: 235ms\n",
      "14:\tlearn: 1.9378345\ttotal: 869ms\tremaining: 174ms\n",
      "15:\tlearn: 1.9012896\ttotal: 915ms\tremaining: 114ms\n",
      "16:\tlearn: 1.8630139\ttotal: 963ms\tremaining: 56.7ms\n",
      "17:\tlearn: 1.8295221\ttotal: 1.01s\tremaining: 0us\n",
      "Model f1_score on test set: 0.1765\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_80 = train_80.set_index('naming_orig')\n",
    "train_hold = train_hold.set_index('naming_orig')\n",
    "\n",
    "X_train = train_80.drop('RMSSE_model', axis=1)\n",
    "y_train = train_80['RMSSE_model']\n",
    "\n",
    "X_test = train_hold.drop('RMSSE_model', axis=1)\n",
    "y_test = train_hold['RMSSE_model']\n",
    "\n",
    "model = CatBoostClassifier(iterations=18,  depth=7, learning_rate = 0.3)\n",
    "#model = CatBoostClassifier(iterations=26,  depth=8, learning_rate = 0.23)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "f1 = f1_score(y_test, y_pred, average = 'weighted')\n",
    "print(f\"Model f1_score on test set: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6889bff9-4530-445d-965e-4a39c59c3486",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def give_results(raw_data, test, predict, criteria):\n",
    "    result = pd.DataFrame(index=criteria,\n",
    "                          columns=['metric', 'model', 'accuracy', 'lost_rate', 'RMSSE'])\n",
    "    assert np.array(test).shape == np.array(predict).shape\n",
    "    result['metric'] = criteria\n",
    "    result['model'] = 'N/A'\n",
    "    \n",
    "    total = len(test)\n",
    "    for criterion in criteria:\n",
    "        # Calculate accuarcy\n",
    "        tp = test[test[criterion+'_model']==predict[criterion+'_model']].count().iloc[0]\n",
    "        \n",
    "        n = 0; mae = 0; lost = 0; rmsse = 0\n",
    "\n",
    "        for ts in test.index:\n",
    "\n",
    "            pred_model = predict.loc[ts, criterion+'_model']\n",
    "            batch = raw_data[raw_data['naming_orig']==ts]\n",
    "            try:\n",
    "                true_value = batch.iloc[batch[criterion].argmin()][criterion]\n",
    "                pred_value = batch[batch['model_name']==pred_model][criterion].iloc[0]\n",
    "                rmsse = rmsse + pred_value\n",
    "                if true_value != pred_value:\n",
    "                    n = n + 1\n",
    "                    mae = mae + np.abs(true_value - pred_value)\n",
    "                    \n",
    "            except:\n",
    "                lost = lost + 1\n",
    "            \n",
    "        #result.loc[criterion, 'MAE'] = mae / n\n",
    "        result.loc[criterion, 'lost_rate'] = lost / total\n",
    "        result.loc[criterion, 'accuracy'] = tp / total\n",
    "        result.loc[criterion, 'RMSSE'] = rmsse / total\n",
    "        result.index = np.arange(len(criteria))\n",
    "            \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8914f5ea-4cb8-422e-93bf-8a4ba8518f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = y_test.reset_index(drop=False)\n",
    "pred['RMSSE_model'] = y_pred[:,0]\n",
    "pred = pred.set_index('naming_orig')\n",
    "y_test = y_test.to_frame('RMSSE_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f74b0634-3888-4301-b369-9853ff906b20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>lost_rate</th>\n",
       "      <th>RMSSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RMSSE</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0.241379</td>\n",
       "      <td>0.005747</td>\n",
       "      <td>0.741224</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  metric model  accuracy lost_rate     RMSSE\n",
       "0  RMSSE   N/A  0.241379  0.005747  0.741224"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_4 = give_results(data[data['split']=='validation'], y_test, pred, ['RMSSE'])\n",
    "exp_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9f433c83-1072-495c-956a-155df8af7007",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 2.9688227\ttotal: 45ms\tremaining: 765ms\n",
      "1:\tlearn: 2.8317443\ttotal: 90.7ms\tremaining: 726ms\n",
      "2:\tlearn: 2.7079429\ttotal: 139ms\tremaining: 693ms\n",
      "3:\tlearn: 2.6069589\ttotal: 185ms\tremaining: 649ms\n",
      "4:\tlearn: 2.4909748\ttotal: 233ms\tremaining: 606ms\n",
      "5:\tlearn: 2.4043156\ttotal: 280ms\tremaining: 560ms\n",
      "6:\tlearn: 2.3370352\ttotal: 331ms\tremaining: 520ms\n",
      "7:\tlearn: 2.2743725\ttotal: 384ms\tremaining: 479ms\n",
      "8:\tlearn: 2.2175726\ttotal: 430ms\tremaining: 430ms\n",
      "9:\tlearn: 2.1703629\ttotal: 477ms\tremaining: 382ms\n",
      "10:\tlearn: 2.1244625\ttotal: 525ms\tremaining: 334ms\n",
      "11:\tlearn: 2.0676530\ttotal: 576ms\tremaining: 288ms\n",
      "12:\tlearn: 2.0272019\ttotal: 623ms\tremaining: 240ms\n",
      "13:\tlearn: 1.9866064\ttotal: 673ms\tremaining: 192ms\n",
      "14:\tlearn: 1.9378345\ttotal: 723ms\tremaining: 145ms\n",
      "15:\tlearn: 1.9012896\ttotal: 769ms\tremaining: 96.1ms\n",
      "16:\tlearn: 1.8630139\ttotal: 815ms\tremaining: 47.9ms\n",
      "17:\tlearn: 1.8295221\ttotal: 860ms\tremaining: 0us\n",
      "Model f1 score on test set: 0.1687\n"
     ]
    }
   ],
   "source": [
    "test_hold = test_hold.set_index('naming_orig')\n",
    "\n",
    "\n",
    "X_train = train_80.drop('RMSSE_model', axis=1)\n",
    "y_train = train_80['RMSSE_model']\n",
    "\n",
    "X_test = test_hold.drop('RMSSE_model', axis=1)\n",
    "y_true = test_hold['RMSSE_model']\n",
    "\n",
    "\n",
    "model = CatBoostClassifier(iterations=18,  depth=7, learning_rate = 0.3)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "f1_t = f1_score(y_true, y_pred, average = 'weighted')\n",
    "print(f\"Model f1 score on test set: {f1_t:.4f}\")\n",
    "#model = XGBClassifier(n_estimators=7, max_depth=2, objective='multi:softmax', learning_rate = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "494ed7f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = y_true.reset_index(drop=False)\n",
    "pred['RMSSE_model'] = y_pred[:,0]\n",
    "pred = pred.set_index('naming_orig')\n",
    "y_true = y_true.to_frame('RMSSE_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4b04224b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>lost_rate</th>\n",
       "      <th>RMSSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RMSSE</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0.241379</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.906462</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  metric model  accuracy lost_rate     RMSSE\n",
       "0  RMSSE   N/A  0.241379       0.0  0.906462"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_5 = give_results(data[data['split']=='test'], y_true, pred, ['RMSSE'])\n",
    "exp_5"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
