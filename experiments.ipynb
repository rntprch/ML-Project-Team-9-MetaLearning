{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 394,
   "id": "ddf92acc-82a9-4b93-b077-9ba6ea0d94bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "id": "9668825d-28ca-4a8c-b7cb-69e9f4624e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from catboost import CatBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "id": "83355175-f778-4bf3-bf76-5028584aeb17",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train_actual.csv')\n",
    "test = pd.read_csv('test_actual.csv')\n",
    "data = pd.read_csv('full.csv')\n",
    "\n",
    "train_80 = train.sample(frac = 0.8, random_state = 42)\n",
    " \n",
    "# Creating dataframe with \n",
    "# rest of the 80% values\n",
    "train_hold = train.drop(train_80.index)\n",
    "\n",
    "test_hold = test.drop(train_80.index)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5970d5f2-15c0-4fdb-935e-069c13eed0bd",
   "metadata": {},
   "source": [
    "# Straightforward solutions\n",
    "Let's assume, that the best method for each time series is the method with the highest number of best results.\n",
    "The accuarcy we get from choosing that method for every time series and the average RMSSE for specified model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "id": "c1ae7ae3-ef8d-4675-851d-9840f4047700",
   "metadata": {},
   "outputs": [],
   "source": [
    "def straightforward(raw_data, best_data, criteria, models):\n",
    "    baseline = pd.DataFrame(index=criteria,\n",
    "                            columns=['metric', 'model', 'accuracy', 'lost_rate', 'RMSSE'])\n",
    "    assert np.array(models).shape == np.array(criteria).shape\n",
    "    baseline['metric'] = criteria\n",
    "    baseline['model'] = models\n",
    "\n",
    "    total = len(best_data)\n",
    "    for criterion, model in zip(criteria, models):\n",
    "        # Calculate accuarcy\n",
    "        tp = best_data[best_data[criterion+'_model']==model].count().iloc[0]\n",
    "        \n",
    "        true_results = raw_data[raw_data['model_name']==model]\n",
    "        n = 0; mae = 0; lost = 0; rmsse = 0\n",
    "        # For each time series calculate discrepancy between best result and\n",
    "        # predicted method\n",
    "        for ts, result in zip(best_data['naming_orig'], best_data[criterion]):\n",
    "            batch = true_results[true_results['naming_orig']==ts]\n",
    "            try:\n",
    "                true_value = batch.iloc[batch[criterion].argmin()][criterion]\n",
    "                rmsse = rmsse + true_value\n",
    "                if true_value != result:\n",
    "                    n = n + 1\n",
    "                    mae = mae + np.abs(true_value - result)\n",
    "            except:\n",
    "                lost = lost + 1\n",
    "            \n",
    "        #baseline.loc[criterion, 'MAE'] = mae / n\n",
    "        baseline.loc[criterion, 'lost_rate'] = lost / total\n",
    "        baseline.loc[criterion, 'accuracy'] = tp / total\n",
    "        baseline.loc[criterion, 'RMSSE'] = rmsse / total\n",
    "        baseline.index = np.arange(len(criteria))\n",
    "            \n",
    "    return baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79e7037b-370b-4dde-9910-dd4bfeda6fd8",
   "metadata": {},
   "source": [
    "## Experiment I\n",
    "We take the most frequent model from the **train** set and apply it to the **train** holdout as a prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "id": "1f5b8077-f7de-4b80-82a8-646c588fb370",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>lost_rate</th>\n",
       "      <th>RMSSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RMSSE</td>\n",
       "      <td>TFTTuningObjective_gl</td>\n",
       "      <td>0.137931</td>\n",
       "      <td>0.103448</td>\n",
       "      <td>0.877375</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  metric                  model  accuracy lost_rate     RMSSE\n",
       "0  RMSSE  TFTTuningObjective_gl  0.137931  0.103448  0.877375"
      ]
     },
     "execution_count": 398,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_train_model = train_80['RMSSE_model'].mode().to_numpy()[0]\n",
    "train_baseline = straightforward(data[data['split']=='validation'],\n",
    "                                 train_hold, ['RMSSE'], [best_train_model])\n",
    "train_baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3526c468-6308-4720-bf33-a23475b3015d",
   "metadata": {},
   "source": [
    "## Experiment II\n",
    "We take the most frequent model from the **train** set and apply it to the **test** holdout as a prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "id": "7d0338d4-e399-4571-9e31-cdff76d98ffb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>lost_rate</th>\n",
       "      <th>RMSSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RMSSE</td>\n",
       "      <td>TFTTuningObjective_gl</td>\n",
       "      <td>0.149425</td>\n",
       "      <td>0.103448</td>\n",
       "      <td>1.001152</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  metric                  model  accuracy lost_rate     RMSSE\n",
       "0  RMSSE  TFTTuningObjective_gl  0.149425  0.103448  1.001152"
      ]
     },
     "execution_count": 399,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_baseline = straightforward(data[data['split']=='test'],\n",
    "                              test_hold, ['RMSSE'], [best_train_model])\n",
    "cv_baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e99d8eb5-5b1b-4f3f-8c46-72354a140ac3",
   "metadata": {},
   "source": [
    "## Experiment III\n",
    "We take models from the **train** holdout and apply them to the **test** holdout as a prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "id": "6a2038d1-bc38-4188-9579-6369cba4ebc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation2test(raw_data, val_data, test_data, criteria):\n",
    "    result = pd.DataFrame(index=criteria,\n",
    "                          columns=['metric', 'model', 'accuracy', 'lost_rate', 'RMSSE'])\n",
    "    assert np.array(val_data).shape == np.array(test_data).shape\n",
    "    result['metric'] = criteria\n",
    "    result['model'] = 'N/A'\n",
    "    \n",
    "    total = len(val_data)\n",
    "    for criterion in criteria:\n",
    "        # Calculate accuarcy\n",
    "        tp = val_data[val_data[criterion+'_model']==test_data[criterion+'_model']].count().iloc[0]\n",
    "        \n",
    "        n = 0; mae = 0; lost = 0; rmsse = 0\n",
    "        \n",
    "        for ts, metric in zip(test_data['naming_orig'], test_data[criterion]):\n",
    "            batch = raw_data[raw_data['naming_orig']==ts]\n",
    "            batch_val = val_data[val_data['naming_orig']==ts]\n",
    "            value = batch[batch['model_name']==batch_val[criterion+'_model'].values[0]]\n",
    "            try:\n",
    "                true_value = value.iloc[value[criterion].argmin()][criterion]\n",
    "                rmsse = rmsse + true_value\n",
    "                if true_value != metric:\n",
    "                    n = n + 1\n",
    "                    mae = mae + np.abs(true_value - metric)\n",
    "            except:\n",
    "                lost = lost + 1\n",
    "            \n",
    "        #result.loc[criterion, 'MAE'] = mae / n\n",
    "        result.loc[criterion, 'lost_rate'] = lost / total\n",
    "        result.loc[criterion, 'accuracy'] = tp / total\n",
    "        result.loc[criterion, 'RMSSE'] = rmsse / total\n",
    "        result.index = np.arange(len(criteria))\n",
    "            \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "id": "a7700ea7-fe62-4fd4-a0e2-c876efad404a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>lost_rate</th>\n",
       "      <th>RMSSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RMSSE</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0.172414</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.892177</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  metric model  accuracy lost_rate     RMSSE\n",
       "0  RMSSE   N/A  0.172414       0.0  0.892177"
      ]
     },
     "execution_count": 401,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val2test = validation2test(data[data['split']=='test'], \n",
    "                           train_hold, test_hold, ['RMSSE'])\n",
    "val2test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa3f3b70-92a6-4ee3-a790-a068f34b63f1",
   "metadata": {},
   "source": [
    "# Classifier solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "id": "4752cbde-2728-4973-9f8b-122edbfa4728",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 2.7321464\ttotal: 125ms\tremaining: 2.13s\n",
      "1:\tlearn: 2.5996624\ttotal: 253ms\tremaining: 2.02s\n",
      "2:\tlearn: 2.4873226\ttotal: 368ms\tremaining: 1.84s\n",
      "3:\tlearn: 2.4121159\ttotal: 477ms\tremaining: 1.67s\n",
      "4:\tlearn: 2.3008217\ttotal: 598ms\tremaining: 1.55s\n",
      "5:\tlearn: 2.2261429\ttotal: 730ms\tremaining: 1.46s\n",
      "6:\tlearn: 2.1665516\ttotal: 857ms\tremaining: 1.35s\n",
      "7:\tlearn: 2.1117317\ttotal: 967ms\tremaining: 1.21s\n",
      "8:\tlearn: 2.0606526\ttotal: 1.08s\tremaining: 1.08s\n",
      "9:\tlearn: 2.0162702\ttotal: 1.2s\tremaining: 956ms\n",
      "10:\tlearn: 1.9760321\ttotal: 1.32s\tremaining: 840ms\n",
      "11:\tlearn: 1.9375247\ttotal: 1.44s\tremaining: 722ms\n",
      "12:\tlearn: 1.9035135\ttotal: 1.56s\tremaining: 600ms\n",
      "13:\tlearn: 1.8730668\ttotal: 1.68s\tremaining: 480ms\n",
      "14:\tlearn: 1.8305909\ttotal: 1.8s\tremaining: 359ms\n",
      "15:\tlearn: 1.7960115\ttotal: 1.92s\tremaining: 240ms\n",
      "16:\tlearn: 1.7658623\ttotal: 2.03s\tremaining: 119ms\n",
      "17:\tlearn: 1.7395577\ttotal: 2.15s\tremaining: 0us\n",
      "Model f1_score on test set: 0.1738\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_80 = train_80.set_index('naming_orig')\n",
    "train_hold = train_hold.set_index('naming_orig')\n",
    "\n",
    "X_train = train_80.drop('RMSSE_model', axis=1)\n",
    "y_train = train_80['RMSSE_model']\n",
    "\n",
    "X_test = train_hold.drop('RMSSE_model', axis=1)\n",
    "y_test = train_hold['RMSSE_model']\n",
    "\n",
    "model = CatBoostClassifier(iterations=18,  depth=7, learning_rate = 0.3)\n",
    "#model = CatBoostClassifier(iterations=26,  depth=8, learning_rate = 0.23)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "f1 = f1_score(y_test, y_pred, average = 'weighted')\n",
    "print(f\"Model f1_score on test set: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "id": "6889bff9-4530-445d-965e-4a39c59c3486",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def give_results(raw_data, test, predict, criteria):\n",
    "    result = pd.DataFrame(index=criteria,\n",
    "                          columns=['metric', 'model', 'accuracy', 'lost_rate', 'RMSSE'])\n",
    "    assert np.array(test).shape == np.array(predict).shape\n",
    "    result['metric'] = criteria\n",
    "    result['model'] = 'N/A'\n",
    "    \n",
    "    total = len(test)\n",
    "    for criterion in criteria:\n",
    "        # Calculate accuarcy\n",
    "        tp = test[test[criterion+'_model']==predict[criterion+'_model']].count().iloc[0]\n",
    "        \n",
    "        n = 0; mae = 0; lost = 0; rmsse = 0\n",
    "\n",
    "        for ts in test.index:\n",
    "\n",
    "            pred_model = predict.loc[ts, criterion+'_model']\n",
    "            batch = raw_data[raw_data['naming_orig']==ts]\n",
    "            try:\n",
    "                true_value = batch.iloc[batch[criterion].argmin()][criterion]\n",
    "                pred_value = batch[batch['model_name']==pred_model][criterion].iloc[0]\n",
    "                rmsse = rmsse + pred_value\n",
    "                if true_value != pred_value:\n",
    "                    n = n + 1\n",
    "                    mae = mae + np.abs(true_value - pred_value)\n",
    "                    \n",
    "            except:\n",
    "                lost = lost + 1\n",
    "            \n",
    "        #result.loc[criterion, 'MAE'] = mae / n\n",
    "        result.loc[criterion, 'lost_rate'] = lost / total\n",
    "        result.loc[criterion, 'accuracy'] = tp / total\n",
    "        result.loc[criterion, 'RMSSE'] = rmsse / total\n",
    "        result.index = np.arange(len(criteria))\n",
    "            \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "id": "8914f5ea-4cb8-422e-93bf-8a4ba8518f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = y_test.reset_index(drop=False)\n",
    "pred['RMSSE_model'] = y_pred[:,0]\n",
    "pred = pred.set_index('naming_orig')\n",
    "y_test = y_test.to_frame('RMSSE_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "id": "f74b0634-3888-4301-b369-9853ff906b20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>lost_rate</th>\n",
       "      <th>RMSSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RMSSE</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0.241379</td>\n",
       "      <td>0.011494</td>\n",
       "      <td>0.751998</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  metric model  accuracy lost_rate     RMSSE\n",
       "0  RMSSE   N/A  0.241379  0.011494  0.751998"
      ]
     },
     "execution_count": 405,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_4 = give_results(data[data['split']=='validation'], y_test, pred, ['RMSSE'])\n",
    "exp_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "id": "9f433c83-1072-495c-956a-155df8af7007",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 2.7321464\ttotal: 131ms\tremaining: 2.22s\n",
      "1:\tlearn: 2.5996624\ttotal: 262ms\tremaining: 2.1s\n",
      "2:\tlearn: 2.4873226\ttotal: 398ms\tremaining: 1.99s\n",
      "3:\tlearn: 2.4121159\ttotal: 530ms\tremaining: 1.85s\n",
      "4:\tlearn: 2.3008217\ttotal: 666ms\tremaining: 1.73s\n",
      "5:\tlearn: 2.2261429\ttotal: 795ms\tremaining: 1.59s\n",
      "6:\tlearn: 2.1665516\ttotal: 920ms\tremaining: 1.45s\n",
      "7:\tlearn: 2.1117317\ttotal: 1.04s\tremaining: 1.3s\n",
      "8:\tlearn: 2.0606526\ttotal: 1.15s\tremaining: 1.15s\n",
      "9:\tlearn: 2.0162702\ttotal: 1.28s\tremaining: 1.02s\n",
      "10:\tlearn: 1.9760321\ttotal: 1.39s\tremaining: 887ms\n",
      "11:\tlearn: 1.9375247\ttotal: 1.51s\tremaining: 756ms\n",
      "12:\tlearn: 1.9035135\ttotal: 1.63s\tremaining: 629ms\n",
      "13:\tlearn: 1.8730668\ttotal: 1.76s\tremaining: 504ms\n",
      "14:\tlearn: 1.8305909\ttotal: 1.88s\tremaining: 376ms\n",
      "15:\tlearn: 1.7960115\ttotal: 2.01s\tremaining: 251ms\n",
      "16:\tlearn: 1.7658623\ttotal: 2.13s\tremaining: 125ms\n",
      "17:\tlearn: 1.7395577\ttotal: 2.23s\tremaining: 0us\n",
      "Model f1 score on test set: 0.2058\n"
     ]
    }
   ],
   "source": [
    "test_hold = test_hold.set_index('naming_orig')\n",
    "\n",
    "\n",
    "X_train = train_80.drop('RMSSE_model', axis=1)\n",
    "y_train = train_80['RMSSE_model']\n",
    "\n",
    "X_test = test_hold.drop('RMSSE_model', axis=1)\n",
    "y_true = test_hold['RMSSE_model']\n",
    "\n",
    "\n",
    "model = CatBoostClassifier(iterations=18,  depth=7, learning_rate = 0.3)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "f1_t = f1_score(y_true, y_pred, average = 'weighted')\n",
    "print(f\"Model f1 score on test set: {f1_t:.4f}\")\n",
    "#model = XGBClassifier(n_estimators=7, max_depth=2, objective='multi:softmax', learning_rate = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "id": "494ed7f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = y_true.reset_index(drop=False)\n",
    "pred['RMSSE_model'] = y_pred[:,0]\n",
    "pred = pred.set_index('naming_orig')\n",
    "y_true = y_true.to_frame('RMSSE_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "id": "4b04224b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>lost_rate</th>\n",
       "      <th>RMSSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RMSSE</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0.252874</td>\n",
       "      <td>0.011494</td>\n",
       "      <td>0.896407</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  metric model  accuracy lost_rate     RMSSE\n",
       "0  RMSSE   N/A  0.252874  0.011494  0.896407"
      ]
     },
     "execution_count": 408,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_5 = give_results(data[data['split']=='test'], y_true, pred, ['RMSSE'])\n",
    "exp_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5291bc6f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
