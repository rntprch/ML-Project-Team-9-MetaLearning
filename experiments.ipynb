{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "ddf92acc-82a9-4b93-b077-9ba6ea0d94bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: catboost in c:\\users\\mekor\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (1.2.3)\n",
      "Requirement already satisfied: graphviz in c:\\users\\mekor\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from catboost) (0.20.2)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\mekor\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from catboost) (3.7.1)\n",
      "Requirement already satisfied: numpy>=1.16.0 in c:\\users\\mekor\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from catboost) (1.24.3)\n",
      "Requirement already satisfied: pandas>=0.24 in c:\\users\\mekor\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from catboost) (2.0.1)\n",
      "Requirement already satisfied: scipy in c:\\users\\mekor\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from catboost) (1.10.1)\n",
      "Requirement already satisfied: plotly in c:\\users\\mekor\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from catboost) (5.20.0)\n",
      "Requirement already satisfied: six in c:\\users\\mekor\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from catboost) (1.16.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\mekor\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas>=0.24->catboost) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\mekor\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas>=0.24->catboost) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\mekor\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas>=0.24->catboost) (2023.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\mekor\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib->catboost) (1.0.7)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\mekor\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib->catboost) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\mekor\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib->catboost) (4.39.4)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\mekor\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib->catboost) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\mekor\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib->catboost) (23.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\mekor\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib->catboost) (9.5.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\mekor\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib->catboost) (3.0.9)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in c:\\users\\mekor\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from plotly->catboost) (8.2.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "9668825d-28ca-4a8c-b7cb-69e9f4624e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from catboost import CatBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "83355175-f778-4bf3-bf76-5028584aeb17",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('./data/full_train.csv')\n",
    "test = pd.read_csv('./data/full_test.csv')\n",
    "data = pd.read_csv('./data/full.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5970d5f2-15c0-4fdb-935e-069c13eed0bd",
   "metadata": {},
   "source": [
    "# Straightforward solutions\n",
    "Let's assume, that the best method for each time series is the method with the highest number of best results.\n",
    "The accuarcy we get from choosing that method for every time series and the MAE between true best error and this method error will be taken as a baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "c1ae7ae3-ef8d-4675-851d-9840f4047700",
   "metadata": {},
   "outputs": [],
   "source": [
    "def straightforward(raw_data, best_data, criteria, models):\n",
    "    baseline = pd.DataFrame(index=criteria,\n",
    "                            columns=['metric', 'model', 'accuracy', 'lost_rate', 'MAE'])\n",
    "    assert np.array(models).shape == np.array(criteria).shape\n",
    "    baseline['metric'] = criteria\n",
    "    baseline['model'] = models\n",
    "\n",
    "    total = len(best_data)\n",
    "    for criterion, model in zip(criteria, models):\n",
    "        # Calculate accuarcy\n",
    "        tp = best_data[best_data[criterion+'-model']==model].count().iloc[0]\n",
    "        \n",
    "        # For remaining FP results caculate MAE w.r.t. designated criterion\n",
    "        # Get all rows with the best model\n",
    "        true_results = raw_data[raw_data['model_name']==model]\n",
    "        n = 0; mae = 0; lost = 0\n",
    "        # For each time series calculate discrepancy between best result and\n",
    "        # predicted method\n",
    "        for ts, result in zip(best_data['naming_orig'], best_data[criterion]):\n",
    "            batch = true_results[true_results['naming_orig']==ts]\n",
    "            try:\n",
    "                true_value = batch.iloc[batch[criterion].argmin()][criterion]\n",
    "                if true_value != result:\n",
    "                    n = n + 1\n",
    "                    mae = mae + np.abs(true_value - result)\n",
    "            except:\n",
    "                lost = lost + 1\n",
    "            \n",
    "        baseline.loc[criterion, 'MAE'] = mae / n\n",
    "        baseline.loc[criterion, 'lost_rate'] = lost / total\n",
    "        baseline.loc[criterion, 'accuracy'] = tp / total\n",
    "        baseline.index = np.arange(len(criteria))\n",
    "            \n",
    "    return baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79e7037b-370b-4dde-9910-dd4bfeda6fd8",
   "metadata": {},
   "source": [
    "## Experiment I\n",
    "We take the most frequent model from the **train** dataset and apply it to the whole **train** dataset as a prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "1f5b8077-f7de-4b80-82a8-646c588fb370",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>lost_rate</th>\n",
       "      <th>MAE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RMSSE</td>\n",
       "      <td>TFTTuningObjective_gl</td>\n",
       "      <td>0.150402</td>\n",
       "      <td>0.12744</td>\n",
       "      <td>0.320506</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  metric                  model  accuracy lost_rate       MAE\n",
       "0  RMSSE  TFTTuningObjective_gl  0.150402   0.12744  0.320506"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_train_model = train['RMSSE-model'].mode().to_numpy()[0]\n",
    "train_baseline = straightforward(data[data['split']=='validation'],\n",
    "                                 train, ['RMSSE'], [best_train_model])\n",
    "train_baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77f138bd-7b19-4f8b-aa0d-b840dcd7ff3c",
   "metadata": {},
   "source": [
    "## Experiment II\n",
    "We take the most frequent model from the **test** dataset and apply it to the whole **test** dataset as a prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "9180f9d9-6bb5-4ac2-ab3b-5b94fd407fa4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>lost_rate</th>\n",
       "      <th>MAE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RMSSE</td>\n",
       "      <td>Prophet</td>\n",
       "      <td>0.214696</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.195196</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  metric    model  accuracy lost_rate       MAE\n",
       "0  RMSSE  Prophet  0.214696       0.0  0.195196"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_test_model = test['RMSSE-model'].mode().to_numpy()[0]\n",
    "test_baseline = straightforward(data[data['split']=='validation'],\n",
    "                                 test, ['RMSSE'], [best_test_model])\n",
    "test_baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3526c468-6308-4720-bf33-a23475b3015d",
   "metadata": {},
   "source": [
    "## Experiment III\n",
    "We take the most frequent model from the **train** dataset and apply it to the whole **test** dataset as a prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "7d0338d4-e399-4571-9e31-cdff76d98ffb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>lost_rate</th>\n",
       "      <th>MAE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RMSSE</td>\n",
       "      <td>TFTTuningObjective_gl</td>\n",
       "      <td>0.097589</td>\n",
       "      <td>0.12744</td>\n",
       "      <td>0.300779</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  metric                  model  accuracy lost_rate       MAE\n",
       "0  RMSSE  TFTTuningObjective_gl  0.097589   0.12744  0.300779"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_baseline = straightforward(data[data['split']=='test'],\n",
    "                              test, ['RMSSE'], [best_train_model])\n",
    "cv_baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e99d8eb5-5b1b-4f3f-8c46-72354a140ac3",
   "metadata": {},
   "source": [
    "## Experiment IV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "6a2038d1-bc38-4188-9579-6369cba4ebc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation2test(raw_data, val_data, test_data, criteria):\n",
    "    result = pd.DataFrame(index=criteria,\n",
    "                          columns=['metric', 'model', 'accuracy', 'lost_rate', 'MAE'])\n",
    "    assert np.array(val_data).shape == np.array(test_data).shape\n",
    "    result['metric'] = criteria\n",
    "    result['model'] = 'N/A'\n",
    "    \n",
    "    total = len(val_data)\n",
    "    for criterion in criteria:\n",
    "        # Calculate accuarcy\n",
    "        tp = val_data[val_data[criterion+'-model']==test_data[criterion+'-model']].count().iloc[0]\n",
    "        \n",
    "        # For remaining FP results caculate MAE w.r.t. designated criterion\n",
    "        # Get all rows with the best model\n",
    "        n = 0; mae = 0; lost = 0\n",
    "        # For each time series calculate discrepancy between best result and\n",
    "        # predicted method\n",
    "        for ts, metric in zip(test_data['naming_orig'], test_data[criterion]):\n",
    "            batch = raw_data[raw_data['naming_orig']==ts]\n",
    "            try:\n",
    "                true_value = batch.iloc[batch[criterion].argmin()][criterion]\n",
    "                if true_value != metric:\n",
    "                    n = n + 1\n",
    "                    mae = mae + np.abs(true_value - result)\n",
    "            except:\n",
    "                lost = lost + 1\n",
    "            \n",
    "        result.loc[criterion, 'MAE'] = mae / n\n",
    "        result.loc[criterion, 'lost_rate'] = lost / total\n",
    "        result.loc[criterion, 'accuracy'] = tp / total\n",
    "        result.index = np.arange(len(criteria))\n",
    "            \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "a7700ea7-fe62-4fd4-a0e2-c876efad404a",
   "metadata": {},
   "outputs": [],
   "source": [
    "val2test = validation2test(data[data['split']=='validation'], \n",
    "                           train, test, ['RMSSE'])\n",
    "val2test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa3f3b70-92a6-4ee3-a790-a068f34b63f1",
   "metadata": {},
   "source": [
    "# Classifier solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "4752cbde-2728-4973-9f8b-122edbfa4728",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 2.8105740\ttotal: 65ms\tremaining: 1.1s\n",
      "1:\tlearn: 2.6663137\ttotal: 126ms\tremaining: 1.01s\n",
      "2:\tlearn: 2.5409175\ttotal: 193ms\tremaining: 964ms\n",
      "3:\tlearn: 2.4399706\ttotal: 257ms\tremaining: 898ms\n",
      "4:\tlearn: 2.3339324\ttotal: 324ms\tremaining: 844ms\n",
      "5:\tlearn: 2.2503682\ttotal: 388ms\tremaining: 777ms\n",
      "6:\tlearn: 2.1868034\ttotal: 452ms\tremaining: 710ms\n",
      "7:\tlearn: 2.1218856\ttotal: 514ms\tremaining: 643ms\n",
      "8:\tlearn: 2.0614959\ttotal: 586ms\tremaining: 586ms\n",
      "9:\tlearn: 2.0110989\ttotal: 652ms\tremaining: 522ms\n",
      "10:\tlearn: 1.9618075\ttotal: 717ms\tremaining: 456ms\n",
      "11:\tlearn: 1.9064416\ttotal: 782ms\tremaining: 391ms\n",
      "12:\tlearn: 1.8683643\ttotal: 851ms\tremaining: 327ms\n",
      "13:\tlearn: 1.8296889\ttotal: 917ms\tremaining: 262ms\n",
      "14:\tlearn: 1.7971875\ttotal: 980ms\tremaining: 196ms\n",
      "15:\tlearn: 1.7691655\ttotal: 1.04s\tremaining: 131ms\n",
      "16:\tlearn: 1.7428628\ttotal: 1.11s\tremaining: 65.5ms\n",
      "17:\tlearn: 1.7055079\ttotal: 1.18s\tremaining: 0us\n",
      "Model accuracy on test set: 0.2989\n"
     ]
    }
   ],
   "source": [
    "train_data = pd.read_csv(\"./data/train_actual.csv\")\n",
    "# train_data.reset_index()\n",
    "# train_data.set_index('naming_orig')\n",
    "# train_data\n",
    "train_data = train_data.set_index('naming_orig')\n",
    "\n",
    "X = train_data.drop('RMSSE_model', axis=1)\n",
    "y = train_data['RMSSE_model']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model = CatBoostClassifier(iterations=18,  depth=7, learning_rate = 0.3)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Model accuracy on test set: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "6889bff9-4530-445d-965e-4a39c59c3486",
   "metadata": {},
   "outputs": [],
   "source": [
    "def index2name(dataset, y):\n",
    "    for i in range(len(y)):\n",
    "        index = y[i,0]\n",
    "        y[i,0] = dataset.iloc[index,0]\n",
    "    return y\n",
    "\n",
    "def give_results(raw_data, test, predict, criteria):\n",
    "    result = pd.DataFrame(index=criteria,\n",
    "                          columns=['metric', 'model', 'accuracy', 'lost_rate', 'MAE'])\n",
    "    assert np.array(test).shape == np.array(predict).shape\n",
    "    result['metric'] = criteria\n",
    "    result['model'] = 'N/A'\n",
    "    \n",
    "    total = len(test)\n",
    "    for criterion in criteria:\n",
    "        # Calculate accuarcy\n",
    "        tp = test[test[criterion+'_model']==predict[criterion+'_model']].count().iloc[0]\n",
    "        \n",
    "        # For remaining FP results caculate MAE w.r.t. designated criterion\n",
    "        # Get all rows with the best model\n",
    "        n = 0; mae = 0; lost = 0\n",
    "        # For each time series calculate discrepancy between best result and\n",
    "        # predicted method\n",
    "        for ts in test.index:\n",
    "            #true_model = test.loc[ts, criterion+'_model']\n",
    "            pred_model = predict.loc[ts, criterion+'_model']\n",
    "            batch = raw_data[raw_data['naming_orig']==ts]\n",
    "            try:\n",
    "                true_value = batch.iloc[batch[criterion].argmin()][criterion]\n",
    "                pred_value = batch[batch['model_name']==pred_model][criterion].iloc[0]\n",
    "                if true_value != pred_value:\n",
    "                    n = n + 1\n",
    "                    mae = mae + np.abs(true_value - pred_value)\n",
    "            except:\n",
    "                lost = lost + 1\n",
    "            \n",
    "        result.loc[criterion, 'MAE'] = mae / n\n",
    "        result.loc[criterion, 'lost_rate'] = lost / total\n",
    "        result.loc[criterion, 'accuracy'] = tp / total\n",
    "        result.index = np.arange(len(criteria))\n",
    "            \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "8914f5ea-4cb8-422e-93bf-8a4ba8518f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = y_test.reset_index(drop=False)\n",
    "pred['RMSSE_model'] = y_pred[:,0]\n",
    "pred = pred.set_index('naming_orig')\n",
    "y_test = y_test.to_frame('RMSSE_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "f74b0634-3888-4301-b369-9853ff906b20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>lost_rate</th>\n",
       "      <th>MAE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RMSSE</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0.298851</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.088534</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  metric model  accuracy lost_rate       MAE\n",
       "0  RMSSE   N/A  0.298851       0.0  0.088534"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_4 = give_results(data[data['split']=='validation'], y_test, pred, ['RMSSE'])\n",
    "exp_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "9f433c83-1072-495c-956a-155df8af7007",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 2.7358668\ttotal: 72.2ms\tremaining: 1.23s\n",
      "1:\tlearn: 2.5945471\ttotal: 142ms\tremaining: 1.14s\n",
      "2:\tlearn: 2.4815120\ttotal: 209ms\tremaining: 1.05s\n",
      "3:\tlearn: 2.3959946\ttotal: 279ms\tremaining: 976ms\n",
      "4:\tlearn: 2.3102687\ttotal: 352ms\tremaining: 916ms\n",
      "5:\tlearn: 2.2251430\ttotal: 422ms\tremaining: 845ms\n",
      "6:\tlearn: 2.1600392\ttotal: 493ms\tremaining: 775ms\n",
      "7:\tlearn: 2.0974175\ttotal: 565ms\tremaining: 706ms\n",
      "8:\tlearn: 2.0402684\ttotal: 635ms\tremaining: 635ms\n",
      "9:\tlearn: 2.0056483\ttotal: 700ms\tremaining: 560ms\n",
      "10:\tlearn: 1.9657452\ttotal: 773ms\tremaining: 492ms\n",
      "11:\tlearn: 1.9132387\ttotal: 843ms\tremaining: 422ms\n",
      "12:\tlearn: 1.8759844\ttotal: 910ms\tremaining: 350ms\n",
      "13:\tlearn: 1.8402355\ttotal: 981ms\tremaining: 280ms\n",
      "14:\tlearn: 1.8133323\ttotal: 1.05s\tremaining: 210ms\n",
      "15:\tlearn: 1.7774503\ttotal: 1.12s\tremaining: 140ms\n",
      "16:\tlearn: 1.7440936\ttotal: 1.19s\tremaining: 70.1ms\n",
      "17:\tlearn: 1.7163924\ttotal: 1.26s\tremaining: 0us\n",
      "Model accuracy on test set: 0.2440\n"
     ]
    }
   ],
   "source": [
    "train_data = pd.read_csv(\"./data/train_actual.csv\")\n",
    "test_data = pd.read_csv(\"./data/test_actual.csv\")\n",
    "\n",
    "train_data = train_data.set_index('naming_orig')\n",
    "test_data = test_data.set_index('naming_orig')\n",
    "\n",
    "X_train = train_data.drop('RMSSE_model', axis=1)\n",
    "y_train = train_data['RMSSE_model']\n",
    "\n",
    "X_test = test_data.drop('RMSSE_model', axis=1)\n",
    "y_true = test_data['RMSSE_model']\n",
    "\n",
    "model = CatBoostClassifier(iterations=18,  depth=7, learning_rate = 0.3)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "print(f\"Model accuracy on test set: {accuracy:.4f}\")\n",
    "#model = XGBClassifier(n_estimators=7, max_depth=2, objective='multi:softmax', learning_rate = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "494ed7f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = y_true.reset_index(drop=False)\n",
    "pred['RMSSE_model'] = y_pred[:,0]\n",
    "pred = pred.set_index('naming_orig')\n",
    "y_true = y_true.to_frame('RMSSE_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "4b04224b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>lost_rate</th>\n",
       "      <th>MAE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RMSSE</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0.243959</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.124881</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  metric model  accuracy lost_rate       MAE\n",
       "0  RMSSE   N/A  0.243959       0.0  0.124881"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_5 = give_results(data[data['split']=='test'], y_true, pred, ['RMSSE'])\n",
    "exp_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5291bc6f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
